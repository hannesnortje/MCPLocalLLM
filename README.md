# MCPLocalLLM â€” Small Coder Model Training with MCP Integration

A locally fine-tuned coding assistant with context preservation and daily learning capabilities, built on the Model Context Protocol (MCP).

**Building a 7B parameter model optimized for M1 Max** that embeds procedural knowledge, custom definitions, and architectural patterns while providing dual-layer context preservation through MCP integration.

Built with the OODATCAA autonomous development loop: Observe â†’ Orient â†’ Decide â†’ Act â†’ Test â†’ Check â†’ Adapt â†’ Archive

---

## âš¡ Quick Start

### 1. Install Dependencies
```bash
cd /path/to/MCPLocalLLM
pip install -e .[dev]
pre-commit install  # optional
```

### 2. Configure Cursor Rules
- Open Cursor â†’ Settings â†’ Rules â†’ **User Rules**
  - Paste contents of `.oodatcaa/config/UserRules.md`
- Open Cursor â†’ Settings â†’ Rules â†’ **Project Rules**
  - Paste contents of `.oodatcaa/config/ProjectRules.md`

### 3. Define Your Product Objective
**Edit `.oodatcaa/objectives/OBJECTIVE.md`** (this is the ONLY file you need to edit):

```markdown
## Vision (Why)
Build a fast CSV parser for data pipelines

## Outcome (What)
- Parse CSV files with 10M+ rows
- Support RFC 4180 spec
- Performance: p95 < 100ms for 100k rows

## Success Criteria (Measurable)
- [ ] Functional: 100% of RFC 4180 test cases pass
- [ ] Performance: Benchmark tests meet p95 threshold
- [ ] Quality: â‰¥ 85% coverage; 0 high-severity audit issues
- [ ] Documentation: README + API docs complete

## Constraints
- Python 3.11+
- Type hints (mypy strict)
- Security: pip-audit clean
```

### 4. Launch the Autonomous System
Open a Cursor chat and paste:
```
Load @Cursor Rules and @Project Rules. 
Run the prompt in .oodatcaa/prompts/negotiator.md exactly. 
Return only file diffs.
```

Click **Run in Background** âœ¨

**That's it!** The Negotiator will coordinate everything and tell you when to launch other agents as work becomes available.

ğŸ“– See `.oodatcaa/AGENT_MANAGEMENT.md` for detailed agent lifecycle management.

---

## ğŸ”— MCP Integration

**Model Context Protocol (MCP)** is the foundation of this training system, providing advanced context preservation, memory management, and vector search capabilities.

### What is MCP?

MCP (Model Context Protocol) is a standardized protocol for AI model context management. It enables:
- **Persistent Memory**: Store and retrieve training examples, patterns, and knowledge
- **Vector Search**: Semantic search across training data and documentation
- **Context Preservation**: Dual-layer system for protecting critical patterns
- **Agent Coordination**: Multi-agent workflow with shared memory

### Why MCP for Training?

Traditional model training lacks context preservation and memory management. MCP solves this by:

1. **Training Data Management**: Store and organize training examples in Qdrant vector database
2. **Pattern Preservation**: Protect learned patterns and definitions during training
3. **Knowledge RAG**: Retrieve relevant examples during training data generation
4. **Multi-Agent Training**: Coordinate planner, builder, tester agents with shared memory

### Key Benefits

- âœ… **Context Preservation**: Two-layer system (context windows + metadata tagging)
- âœ… **Vector Search**: Fast semantic search across 1k-5k training examples
- âœ… **Memory Management**: Organized storage (global, learned, agent-specific)
- âœ… **Agent Coordination**: MCP protocol enables multi-agent training workflows
- âœ… **Local-First**: No cloud dependencies, runs entirely on M1 Max

### Architecture Overview

```
Training System
â”œâ”€â”€ MCP Server (stdio protocol)
â”‚   â”œâ”€â”€ Memory Management (add, query, update, delete)
â”‚   â”œâ”€â”€ Vector Operations (Qdrant client)
â”‚   â”œâ”€â”€ Policy System (rule compliance)
â”‚   â””â”€â”€ Agent Registry (coordination)
â”‚
â”œâ”€â”€ Qdrant Vector Database
â”‚   â”œâ”€â”€ Training Examples Collection
â”‚   â”œâ”€â”€ Policy Documents Collection
â”‚   â””â”€â”€ Agent Memory Collections
â”‚
â””â”€â”€ Training Pipeline
    â”œâ”€â”€ Data Generation â†’ MCP query for relevant examples
    â”œâ”€â”€ QLoRA Training â†’ Model fine-tuning with context
    â”œâ”€â”€ Validation â†’ MCP-based quality checks
    â””â”€â”€ Deployment â†’ Ollama/MLX serving
```

### MCP Collections

| Collection | Purpose | Size |
|-----------|---------|------|
| `global_memory` | Training examples, patterns | 1k-5k entries |
| `learned_memory` | User corrections, new patterns | Growing |
| `policy_memory` | Rule compliance, definitions | ~50 rules |
| `agent_registry` | Multi-agent coordination | Per agent |

### ğŸ“š Learn More

- **[MCP API Reference](docs/mcp/API.md)** - Complete API documentation
- **[Architecture Details](docs/mcp/mcp-qdrant-reference-architecture.md)** - Deep dive into MCP + Qdrant
- **[Deployment Guide](docs/mcp/DEPLOYMENT.md)** - Production deployment
- **[Troubleshooting](docs/mcp/TROUBLESHOOTING.md)** - Common issues and solutions

---

## ğŸ›  Setup & Installation

Complete setup guide for the MCP Local LLM training system.

### Prerequisites

Before you begin, ensure you have:

- **Python 3.11 or 3.12** (required)
- **32GB RAM** (recommended for M1 Max)
- **Docker Desktop** (optional, for Qdrant vector database)
- **Git** (for version control)
- **pip** (Python package manager)

### Step 1: Clone and Navigate

```bash
git clone <repository-url>
cd MCPLocalLLM
```

### Step 2: Run Automated Setup

The setup script will create a virtual environment, install dependencies, and configure the project:

```bash
./scripts/setup-dev.sh
```

This script will:
- âœ… Check Python version (3.11+)
- âœ… Create virtual environment (`.venv/`)
- âœ… Install Python dependencies
- âœ… Create required directories (`data/`, `logs/`, `policy/`)
- âœ… Copy configuration templates (`.env.example` â†’ `.env`, `config.example.yaml` â†’ `config.yaml`)
- âœ… Verify Docker availability (optional)
- âœ… Display setup summary

### Step 3: Validate Environment

Verify your environment is correctly configured:

```bash
make validate-env
# or: python scripts/validate-env.py
```

This will check:
- âœ… Python version compatibility
- âœ… Virtual environment activated
- âœ… Required directories exist
- âœ… Configuration files present
- âœ… Python dependencies installed
- âš ï¸ Docker availability (optional)
- âš ï¸ Qdrant connection (optional)

### Step 4: Configure Environment Variables

Edit `.env` to customize your setup:

```bash
# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_MODE=local

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
EMBEDDING_DEVICE=cpu

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/mcp-server.log

# Training-specific
MARKDOWN_CHUNK_SIZE=1000
MARKDOWN_CHUNK_OVERLAP=200
```

See `.env.example` for all available options and documentation.

### Step 5: Start Qdrant (Optional)

If using Docker for Qdrant:

```bash
docker-compose up -d qdrant
```

Verify Qdrant is running:
```bash
curl http://localhost:6333/health
```

### Configuration Files

**`.env`** â€” Environment variables for runtime configuration
- Qdrant connection settings
- Embedding model configuration
- Logging levels
- Training parameters

**`config.yaml`** â€” Application configuration
- Server name and mode
- Memory management settings
- Policy system configuration
- Search and retrieval parameters

Both files are created from templates during setup. Customize as needed for your training workflow.

### Troubleshooting

#### Issue 1: Python Version Mismatch
**Problem:** Setup script fails with "Python 3.11+ required"
**Solution:** 
```bash
# Install Python 3.11+ using pyenv or system package manager
pyenv install 3.11.9
pyenv local 3.11.9
```

#### Issue 2: Virtual Environment Not Activated
**Problem:** Dependencies not found or wrong Python version
**Solution:**
```bash
source .venv/bin/activate  # On Linux/Mac
# or
.venv\Scripts\activate  # On Windows
```

#### Issue 3: Docker/Qdrant Connection Failed
**Problem:** Validation fails with Qdrant connection error
**Solution:** 
- Docker is **optional** for development
- Start Qdrant: `docker-compose up -d qdrant`
- Or use Qdrant in memory mode (no Docker needed)

#### Issue 4: Permission Denied on Setup Script
**Problem:** `bash: ./scripts/setup-dev.sh: Permission denied`
**Solution:**
```bash
chmod +x scripts/setup-dev.sh
./scripts/setup-dev.sh
```

#### Issue 5: Missing Dependencies
**Problem:** Import errors or missing packages
**Solution:**
```bash
pip install -e ".[dev]"  # Reinstall all dependencies
```

For more troubleshooting, see `docs/mcp/TROUBLESHOOTING.md` or check the validation output for specific issues.

---

## ğŸ— Architecture: MCP-Enabled Training System

This section explains how MCP integration enables the small coder model training workflow.

### Training Pipeline with MCP

The training system leverages MCP for three critical functions:

1. **Training Data Management**
   - Store training examples in Qdrant vector database
   - Semantic search for relevant examples during data generation
   - Organize by memory type (global, learned, agent-specific)
   - Deduplicate and version training examples

2. **Context Preservation**
   - **Layer 1: Context Window Replacement** - Proactive education (future)
   - **Layer 2: Metadata Tagging** - Protective contracts (future)
   - Policy system enforces rule compliance during training
   - Preserve critical patterns and definitions in model weights

3. **Agent Coordination**
   - Multi-agent training workflow (Planner, Builder, Tester, Refiner, Integrator)
   - Shared memory across agents via MCP protocol
   - Coordinated through Negotiator with MCP state tracking

### Qdrant Vector Database Role

**Qdrant** provides the vector search foundation for MCP:

- **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions, CPU-optimized for M1 Max)
- **Chunk Size**: 1000 characters (training-optimized context windows)
- **Similarity Threshold**: 0.8 (balanced precision/recall)
- **Collections**: Separate namespaces for different memory types
- **Performance**: Sub-second semantic search across 1k-5k training examples

### Training Workflow Integration Points

```
Phase 1: Data Generation
â”œâ”€â”€ User provides examples/corrections
â”œâ”€â”€ MCP Server: Store in learned_memory collection
â”œâ”€â”€ Qdrant: Vector embedding + indexing
â””â”€â”€ RAG Query: Retrieve similar examples for context

Phase 2: Training Data Preparation
â”œâ”€â”€ Query MCP: Get all training examples
â”œâ”€â”€ Enhance with RAG context from similar examples
â”œâ”€â”€ Apply policy rules for pattern preservation
â””â”€â”€ Generate training dataset (1k-5k examples)

Phase 3: QLoRA Training
â”œâ”€â”€ Fine-tune Qwen2.5-Coder-7B with QLoRA (rank=16)
â”œâ”€â”€ Train on M1 Max (32GB RAM, 6-24 hours)
â”œâ”€â”€ Preserve procedural knowledge and custom definitions
â””â”€â”€ Export to GGUF Q4_K_M (â‰¤8GB quantized)

Phase 4: Validation & Deployment
â”œâ”€â”€ MCP-based quality checks (pattern preservation)
â”œâ”€â”€ Validate against policy compliance rules
â”œâ”€â”€ Deploy to Ollama/MLX for local inference
â””â”€â”€ Monitor and iterate based on user feedback
```

### Dual-Layer Context Preservation (Future)

The training system is designed for dual-layer context preservation (to be implemented in Sprint 2+):

- **Context Window Replacement**: Proactively educate Cursor IDE with system prompts and active rules
- **Metadata Tagging**: Protect individual responses with preservation levels (strict/moderate/flexible)
- **Rule Compliance**: Dynamic pattern-based categories (concept:*, pattern:*, definition:*)
- **Source Validation**: Respect responses marked with `source: "local_trained_model"`

This dual-layer approach ensures trained patterns persist across IDE sessions and model updates.

### MCP Protocol Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         stdio          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cursor IDE    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   MCP Server    â”‚
â”‚  (Client)       â”‚   JSON-RPC messages   â”‚  (Python)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â”‚ HTTP/gRPC
                                                    â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚     Qdrant      â”‚
                                           â”‚  Vector DB      â”‚
                                           â”‚  (Docker)       â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **stdio Protocol**: MCP Server communicates with Cursor via stdin/stdout
- **JSON-RPC**: Standardized message format for tool calls and responses
- **HTTP/gRPC**: MCP Server connects to Qdrant for vector operations
- **Local-First**: All components run on M1 Max, no cloud dependencies

---

## ğŸ¤– What Happens Next (Fully Autonomous)

1. **Negotiator** starts and reads your OBJECTIVE.md
2. Negotiator tells you: "âš ï¸ LAUNCH AGENT: Sprint Planner"
3. You launch **Sprint Planner** â†’ generates Sprint 1 goal
4. Negotiator tells you: "âš ï¸ LAUNCH AGENT: Planner"
5. You launch **Planner** â†’ breaks tasks into detailed plans
6. Negotiator tells you: "âš ï¸ LAUNCH AGENT: Builder"
7. You launch **Builder(s)** â†’ implement features on branches
8. Negotiator tells you: "âš ï¸ LAUNCH AGENT: Tester"
9. You launch **Tester** â†’ validates acceptance criteria
10. Negotiator coordinates **Integrator** â†’ merges PRs and tags releases
11. **Sprint Planner** detects when project is 100% complete

**The Negotiator guides you!** It will tell you exactly when and which agents to launch.

**You just watch the agents work!** Monitor progress in:
- `.oodatcaa/objectives/SPRINT_GOAL.md` â€” Current sprint & progress
- `.oodatcaa/work/AGENT_LOG.md` â€” Detailed execution log
- `.oodatcaa/work/SPRINT_LOG.md` â€” Sprint summaries

When complete, agents generate `.oodatcaa/objectives/PROJECT_COMPLETION_REPORT.md`

---

## ğŸ“– Sprint 1 Journey: MCP Server Migration

**Sprint 1 Goal**: Migrate and integrate MCP server infrastructure for small coder model training.

### Migration Overview

Sprint 1 successfully migrated the complete MCP server from `/media/hannesn/storage/Code/MCP/` to this training project, establishing the foundation for context-aware model training.

**Timeline**: October 1-3, 2025 (3 days, fully autonomous execution)  
**Tasks Completed**: 32 of 37 (86.5% complete)  
**Agent Coordination**: Negotiator + Planner + Builder + Tester + Refiner + Integrator

### Key Achievements

| Task | Description | Result |
|------|-------------|--------|
| **W001** | Analyze MCP source structure | âœ… 61 essential files identified |
| **W002** | Execute MCP server migration | âœ… Complete file migration, zero conflicts |
| **W003** | Integrate MCP dependencies | âœ… All dependencies resolved |
| **W004** | Adapt MCP for training use case | âœ… 88.97% error reduction (390â†’43 ruff errors) |
| **W005** | Python tooling & quality gates | âœ… 34.9% further improvement (43â†’28 ruff errors) |
| **W006** | Basic integration testing | âœ… 13 integration tests, 100% pass rate |
| **W007** | Configuration & environment setup | âœ… Complete setup automation |
| **W008** | Documentation update | ğŸš§ In progress (this document) |

### Quality Metrics

- **Files Migrated**: 61 essential MCP files (src/mcp_local/, 47 modules)
- **Code Quality**: Ruff errors reduced by 92.8% (390â†’28)
- **Test Coverage**: 13 integration tests (10 passing, 3 skipped)
- **Zero Regressions**: All existing functionality preserved
- **Configuration**: Complete .env.example, config.example.yaml, docker-compose.yml
- **Documentation**: Setup automation with `scripts/setup-dev.sh` and `scripts/validate-env.py`

### Adaptation & Iteration

Sprint 1 demonstrated the power of the OODATCAA adaptive loop:

- **W004**: 3 adaptation iterations â†’ 88.97% error reduction
- **W005**: 2 adaptation iterations â†’ Additional 34.9% improvement
- **W006-B01**: 2 adaptation iterations â†’ Import conflict resolved, API corrections applied
- **W007-B01**: 1 adaptation iteration â†’ Documentation complete, quality improved

**Total Adaptation Cycles**: 4  
**Adaptation Success Rate**: 100%  
**Average Adaptation Time**: ~35 minutes per iteration

### Lessons Learned

1. **Incremental Migration Works**: Breaking migration into W001 (analyze) â†’ W002 (copy) â†’ W003 (integrate) prevented "big bang" failures
2. **Quality Gates Pay Off**: Early investment in W004-W005 quality work prevented technical debt
3. **Adaptation is Faster than Rollback**: Quick fixes (35-50 min) more efficient than Start-Over Gate
4. **Test Infrastructure First**: W006 integration tests caught issues early, prevented regressions

### What's Next (Sprint 2+)

With MCP infrastructure complete, Sprint 2 will focus on:
- **Training Data Generation**: Use MCP to store and retrieve training examples
- **QLoRA Training Pipeline**: Implement Qwen2.5-Coder-7B fine-tuning with QLoRA
- **Dual-Layer Context Preservation**: Implement context window replacement + metadata tagging
- **Daily Learning System**: Automated overnight training with MCP-based insight capture

**Full Sprint 1 Details**: See `CHANGELOG.md` for complete task-by-task breakdown with commits, PRs, and metrics.

---

## Repository Structure

```
.
â”œâ”€â”€ .oodatcaa/                      # All OODATCAA system files
â”‚   â”œâ”€â”€ config/                     # Cursor Rules
â”‚   â”‚   â”œâ”€â”€ UserRules.md            # Global multi-agent doctrine
â”‚   â”‚   â””â”€â”€ ProjectRules.md         # Python-specific commands & gates
â”‚   â”œâ”€â”€ objectives/                 # Strategic planning
â”‚   â”‚   â”œâ”€â”€ OBJECTIVE.md            # Product objective (what & why)
â”‚   â”‚   â”œâ”€â”€ SPRINT_GOAL.md          # Sprint exit criteria
â”‚   â”‚   â””â”€â”€ RELEASE_CHECKLIST.md    # Release checklist
â”‚   â”œâ”€â”€ work/                       # Active sprint work
â”‚   â”‚   â”œâ”€â”€ SPRINT_BACKLOG.md       # Sprint backlog items
â”‚   â”‚   â”œâ”€â”€ SPRINT_PLAN.md          # Current sprint assignments
â”‚   â”‚   â”œâ”€â”€ AGENT_PLAN.md           # Detailed implementation plan
â”‚   â”‚   â”œâ”€â”€ TEST_PLAN.md            # Test commands & acceptance criteria
â”‚   â”‚   â”œâ”€â”€ AGENT_LOG.md            # Append-only execution log
â”‚   â”‚   â”œâ”€â”€ SPRINT_LOG.md           # Sprint summary & decisions
â”‚   â”‚   â””â”€â”€ SPRINT_QUEUE.json       # Work queue with status & deps
â”‚   â”œâ”€â”€ prompts/                    # Agent prompt templates
â”‚   â””â”€â”€ scripts/                    # Helper scripts (lease.sh, lock.sh)
â”œâ”€â”€ docs/                           # Project documentation
â”‚   â”œâ”€â”€ CONTRIBUTING.md
â”‚   â”œâ”€â”€ SECURITY.md
â”‚   â””â”€â”€ BRANCH_PROTECTION.md
â”œâ”€â”€ src/app_pkg/                    # Source code
â”œâ”€â”€ tests/                          # Tests (unit + acceptance)
â””â”€â”€ .github/                        # CI workflows
```

## Development Commands

```bash
# Format code
make fmt

# Run all gates
make gates

# Run tests
make test

# Full check (gates + tests + coverage)
make check

# Build package
make build

# Security audit
make audit

# Create baseline tag
make tag TICKET=W123

# Rollback to baseline
make rollback TAG=pre/W123-YYYY-MM-DDTHH-MM-SS

# Sprint Management (P003)
make sprint-status              # View real-time sprint dashboard
make sprint-complete            # Finalize sprint (when exit criteria met)
make sprint-new                 # Initialize next sprint
```

### Sprint Management System

The project includes automated sprint management tools for monitoring progress, completing sprints, and initializing new sprints.

**Key Commands:**

- **`make sprint-status`** - Real-time sprint dashboard showing:
  - Progress percentage and task breakdown
  - WIP utilization per agent role
  - Exit criteria status
  - Recent activity and next actions
  - Generates `.oodatcaa/work/SPRINT_STATUS.json` for automation

- **`make sprint-complete`** - Sprint finalization (requires exit criteria met):
  - Archives all logs to `archive/sprint_N/`
  - Generates sprint retrospective
  - Creates git tag `sprint-N-complete`
  - Updates SPRINT_QUEUE.json status

- **`make sprint-new`** - Initialize next sprint:
  - Increments sprint number automatically
  - Creates new directory structure
  - Resets logs and queue
  - Cleans up stale leases/locks

**Documentation:** See [`docs/SPRINT_MANAGEMENT.md`](docs/SPRINT_MANAGEMENT.md) for detailed usage, troubleshooting, and SPRINT_STATUS.json schema.

**Example Workflow:**
```bash
# Monitor current sprint
make sprint-status

# When all exit criteria complete
make sprint-complete   # Finalize Sprint 2

# Start next sprint
make sprint-new        # Initialize Sprint 3
```

## ğŸ¯ Autonomous Workflow

The system operates in a continuous loop:

```
User: Define OBJECTIVE.md
  â†“
Negotiator: Check if sprint exists
  â†“ (no sprint)
Sprint Planner: Generate Sprint 1 goal from objective
  â†“
Planner: Break sprint into detailed tasks
  â†“
Builder(s): Implement features in parallel
  â†“
Tester: Validate acceptance criteria
  â†“
Integrator: Merge PRs, tag releases
  â†“
Negotiator: Check sprint completion
  â†“
Sprint Planner: Generate Sprint 2 (or declare project complete)
  â†“
... repeat until 100% objective achieved
```

### Key Features
- **Zero manual sprint planning** â€” Agents decide scope and timeline
- **Autonomous completion detection** â€” Agents know when project is done
- **Adaptive** â€” Refiner handles failures; Sprint Planner adjusts course
- **Parallel work** â€” Multiple builders work simultaneously
- **Full traceability** â€” Every decision logged

---

## ğŸ“š Additional Documentation

### MCP-Specific Documentation

Comprehensive MCP integration documentation is available in `docs/mcp/`:

| Document | Description |
|----------|-------------|
| **[API.md](docs/mcp/API.md)** | Complete MCP API reference - all tools, resources, prompts |
| **[DEPLOYMENT.md](docs/mcp/DEPLOYMENT.md)** | Production deployment guide for MCP server + Qdrant |
| **[mcp-qdrant-reference-architecture.md](docs/mcp/mcp-qdrant-reference-architecture.md)** | Detailed MCP + Qdrant architecture and design decisions |
| **[TROUBLESHOOTING.md](docs/mcp/TROUBLESHOOTING.md)** | MCP-specific troubleshooting and common issues |
| **[GUIDANCE_CONTENT.md](docs/mcp/GUIDANCE_CONTENT.md)** | MCP guidance system and content generation |
| **[PROMPT_EXAMPLES.md](docs/mcp/PROMPT_EXAMPLES.md)** | Example prompts for MCP tool usage |
| **[DUAL_LINK_FEASIBILITY_REPORT.md](docs/mcp/DUAL_LINK_FEASIBILITY_REPORT.md)** | Dual-layer context preservation feasibility analysis |

### Project Documentation

| Document | Description |
|----------|-------------|
| **[CHANGELOG.md](CHANGELOG.md)** | Complete Sprint 1 changelog with all W001-W008 tasks |
| **[CONTRIBUTING.md](docs/CONTRIBUTING.md)** | Contribution guidelines and development workflow |
| **[SECURITY.md](docs/SECURITY.md)** | Security policy and vulnerability reporting |
| **[BRANCH_PROTECTION.md](docs/BRANCH_PROTECTION.md)** | Git workflow and branch protection rules |
| **[BACKGROUND_AGENTS.md](docs/BACKGROUND_AGENTS.md)** | Background agent daemon system documentation |

### OODATCAA System Documentation

Internal documentation for the autonomous development system:

| Document | Description |
|----------|-------------|
| **`.oodatcaa/config/UserRules.md`** | Multi-agent doctrine and coordination rules |
| **`.oodatcaa/config/ProjectRules.md`** | Python-specific commands and quality gates |
| **`.oodatcaa/AGENT_MANAGEMENT.md`** | Agent lifecycle management guide |
| **`.oodatcaa/AGENT_ROLES_MATRIX.md`** | 11 agents documented (roles, responsibilities, I/O, decision authority) |
| **`.oodatcaa/AGENT_INTERACTION_GUIDE.md`** | Workflow patterns, communication mechanisms, 4 protocols, best practices |
| **`.oodatcaa/work/AGENT_GAP_ANALYSIS.md`** | System gap analysis, 13 gaps identified, 7 recommendations, roadmap |
| **`.oodatcaa/work/SPRINT_LOG.md`** | Sprint summaries and retrospectives |
| **`.oodatcaa/work/AGENT_LOG.md`** | Detailed agent execution log |

---

## License

See LICENSE file.

