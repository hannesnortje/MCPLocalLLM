# MCP Local LLM - Environment Configuration Template
# Copy this file to .env and customize for your environment
# IMPORTANT: Never commit .env to version control (already in .gitignore)

# ============================================================================
# Qdrant Configuration
# ============================================================================
# Qdrant vector database connection settings for local training environment

# Qdrant host (use "localhost" for local development, Docker will resolve "qdrant" internally)
QDRANT_HOST=localhost

# Qdrant HTTP API port (default: 6333)
QDRANT_PORT=6333

# Qdrant API key (optional, only required for Qdrant Cloud mode)
# For local development, leave empty
QDRANT_API_KEY=

# ============================================================================
# Embedding Model Configuration
# ============================================================================
# Settings for sentence-transformers embedding model

# Embedding model name (default: all-MiniLM-L6-v2, 384 dimensions)
# This is optimized for CPU inference on M1 Max
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding vector dimension (must match model: all-MiniLM-L6-v2 = 384)
EMBEDDING_DIMENSION=384

# Device for embedding inference (cpu or cuda)
# For Apple Silicon (M1 Max), use "cpu" (MPS not well supported by sentence-transformers)
EMBEDDING_DEVICE=cpu

# Cache folder for downloaded models (optional, default: ~/.cache/huggingface)
EMBEDDING_CACHE_FOLDER=

# ============================================================================
# Markdown Processing Configuration
# ============================================================================
# Settings for processing markdown documents for training data

# Chunk size for splitting markdown documents (characters)
# Training optimized: 1000 chars provides good context windows
CHUNK_SIZE=1000

# Chunk overlap for context preservation (characters)
# 200 chars overlap ensures continuity between chunks
CHUNK_OVERLAP=200

# ============================================================================
# Memory & Search Configuration
# ============================================================================
# Settings for vector similarity search and memory retrieval

# Similarity threshold for vector search (0.0-1.0)
# 0.8 = good balance for training context retrieval
SIMILARITY_THRESHOLD=0.8

# Maximum number of results to return from search
MAX_RESULTS=10

# ============================================================================
# Agent Configuration
# ============================================================================
# Default agent ID for training agent coordination

# Default agent identifier (used if no agent_id provided)
DEFAULT_AGENT_ID=training-agent

# ============================================================================
# Logging Configuration
# ============================================================================
# Logging settings for development and debugging

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use INFO for training, DEBUG for troubleshooting
LOG_LEVEL=INFO

# Log file path (optional, if not set logs go to stdout only)
LOG_FILE=

# ============================================================================
# Policy System Configuration
# ============================================================================
# Settings for policy document management and rule compliance

# Directory containing policy markdown files
POLICY_DIRECTORY=./policy

# ============================================================================
# Server Configuration (for MCP protocol)
# ============================================================================
# MCP server metadata and protocol settings

# Server name identifier
MCP_SERVER_NAME=mcp-local-llm-training

# ============================================================================
# Training-Specific Configuration
# ============================================================================
# Additional settings specific to small coder model training

# Qdrant mode: "local" for development, "remote" for Docker, "cloud" for Qdrant Cloud
QDRANT_MODE=local

# Markdown chunk size for training data generation
MARKDOWN_CHUNK_SIZE=1000

# Markdown chunk overlap for training data
MARKDOWN_CHUNK_OVERLAP=200

# Memory deduplication threshold (0.0-1.0)
# Higher = stricter deduplication (0.95 = 95% similar content is duplicate)
MEMORY_DEDUPLICATION_THRESHOLD=0.95

# ============================================================================
# Notes
# ============================================================================
# - This configuration is optimized for Apple M1 Max (32GB RAM) local training
# - For production deployment, update QDRANT_HOST, LOG_LEVEL, and security settings
# - All paths are relative to project root unless absolute paths provided
# - Docker Compose will use internal service names (e.g., QDRANT_HOST=qdrant)
