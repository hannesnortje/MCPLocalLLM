version: '3.8'

# Training Environment Configuration
# Optimized for small coder model training on Apple M1 Max (32GB RAM)
# This setup provides local Qdrant for training data storage and retrieval

services:
  # Qdrant Vector Database - Training Mode
  # Stores training data, embeddings, and policy documents for small coder model
  qdrant:
    image: qdrant/qdrant:latest
    container_name: mcp-qdrant-training  # Training-specific container name
    ports:
      - "6333:6333"  # HTTP API port (for MCP server communication)
      - "6334:6334"  # gRPC port (optional, for high-performance access)
    volumes:
      - qdrant_data:/qdrant/storage  # Persistent storage for training data
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s  # Allow extra time for M1 Max initialization
    restart: unless-stopped
    networks:
      - mcp-network

  # MCP Memory Server - Training Mode
  # Handles training data generation, context preservation, and policy management
  mcp-server:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: mcp-local-llm-server  # Training-specific server name
    depends_on:
      qdrant:
        condition: service_healthy
    environment:
      # Server Configuration (Training Mode)
      - MCP_SERVER_NAME=mcp-local-llm-training
      - LOG_LEVEL=INFO  # Use DEBUG for training troubleshooting
      - LOG_FILE=/app/logs/server.log
      
      # Qdrant Configuration (Docker internal networking)
      - QDRANT_HOST=qdrant  # Use Docker service name for internal communication
      - QDRANT_PORT=6333
      - QDRANT_MODE=remote  # "remote" mode for Docker-to-Docker communication
      
      # Embedding Configuration (Training Optimized)
      - EMBEDDING_MODEL=all-MiniLM-L6-v2  # Lightweight, fast, CPU-friendly
      - EMBEDDING_DEVICE=cpu  # CPU inference for M1 Max compatibility
      - EMBEDDING_CACHE_FOLDER=/app/data/embeddings
      
      # Training Data Generation Settings
      - MARKDOWN_CHUNK_SIZE=1000  # Optimal context window size for training
      - MARKDOWN_CHUNK_OVERLAP=200  # Ensures continuity in training examples
      - MEMORY_DEDUPLICATION_THRESHOLD=0.95  # High threshold prevents duplicate training data
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./policy:/app/policy
      - ./docs:/app/docs:ro
    networks:
      - mcp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import src.server_config; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Optional: Monitoring with Prometheus (commented out by default)
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: mcp-prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #   networks:
  #     - mcp-network
  #   restart: unless-stopped

  # Optional: Log aggregation with ELK stack (commented out by default)
  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
  #   container_name: mcp-elasticsearch
  #   environment:
  #     - discovery.type=single-node
  #     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  #   volumes:
  #     - elasticsearch_data:/usr/share/elasticsearch/data
  #   networks:
  #     - mcp-network
  #   restart: unless-stopped

volumes:
  qdrant_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  mcp-network:
    driver: bridge